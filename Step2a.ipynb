{"cells":[{"cell_type":"markdown","metadata":{"id":"jvwYB216eZms"},"source":["Set Up and Environment"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"I-chpoGaem8J"},"outputs":[],"source":["!pip install ptflops"]},{"cell_type":"code","source":["!pip install -U fvcore"],"metadata":{"id":"_icaP9jnV1Yp"},"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"b4b63252"},"source":["!pip install albumentations"],"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":26648,"status":"ok","timestamp":1756916091815,"user":{"displayName":"GruppoBIxDB","userId":"02526103203990742405"},"user_tz":-120},"id":"EPxu1_l1egKk","outputId":"9bbce710-fdd1-45ba-c1e2-b59f179b4a45"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["## Import and setup ##\n","\n","import os, time, zipfile, gc, glob, torch\n","import numpy as np\n","from PIL import Image\n","from collections import deque\n","\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from torch.utils.data import Dataset, DataLoader\n","from torchvision import transforms\n","import albumentations as A\n","from albumentations.pytorch import ToTensorV2\n","\n","from ptflops import get_model_complexity_info\n","from google.colab import drive\n","\n","from fvcore.nn import FlopCountAnalysis, flop_count_table\n","\n","\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","drive.mount(\"/content/drive\", force_remount=True)\n"]},{"cell_type":"markdown","metadata":{"id":"dMByo77ZfX1S"},"source":["Image preprocessing for training and validation datasets.\n","The transformations include:\n","1. Resizing all input images to 512x1024 pixels.\n","2. Normalizing pixel values using ImageNet statistics\n"," (mean and standard deviation per channel).\n","3. Converting images to PyTorch tensors"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wdIvsUFmO538"},"outputs":[],"source":["## Transform ##\n","\n","train_transform = A.Compose([\n","    A.Resize(height=512, width=1024),A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)), ToTensorV2()])\n","\n","val_transform = A.Compose([\n","    A.Resize(height=512, width=1024), A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),ToTensorV2()])\n"]},{"cell_type":"markdown","metadata":{"id":"jFVOMhTRfb_O"},"source":["Cityscapes Dataset and DataLoader Setup.\n","\n","This section defines a PyTorch Dataset class for loading the Cityscapes\n","dataset.\n","DataLoaders are then created for both training and validation step."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"j_PqLU0UG9EO"},"outputs":[],"source":["## Dataset Cityscapes ##\n","\n","class CityscapesDataset(Dataset):\n","    def __init__(self, root, split=\"train\", transform=None):\n","        self.transform = transform\n","        self.images = sorted(glob.glob(f\"{root}/images/{split}/**/*.png\", recursive=True))\n","        self.labels = sorted(glob.glob(f\"{root}/gtFine/{split}/**/*_labelTrainIds.png\", recursive=True))   # TrainId are extracted\n","\n","        min_lenght = min(len(self.images), len(self.labels))\n","        self.images = self.images[:min_lenght]\n","        self.labels = self.labels[:min_lenght]\n","\n","    def __len__(self):\n","        # Return the number of images\n","        return len(self.images)\n","\n","    def __getitem__(self, idx):\n","        img = np.array(Image.open(self.images[idx]).convert(\"RGB\"))\n","        label = np.array(Image.open(self.labels[idx]), dtype=np.int64)\n","\n","        if self.transform:\n","            # Apply the training transformation to image and mask\n","            transformed_img_lab = self.transform(image=img, mask=label)\n","            # Extract the transformed image and mask\n","            img = transformed_img_lab['image']\n","            label = transformed_img_lab['mask']\n","\n","        # Converting label to LongTensor\n","        if isinstance(label, np.ndarray):\n","            label = torch.from_numpy(label).long()\n","        else:\n","            label = label.long()\n","\n","        return img, label\n","\n","\n","## Create datasets for training and validation ##\n","\n","train_dataset = CityscapesDataset(root=\"/content/drive/MyDrive/Cityscapes/Cityspaces\", split=\"train\", transform=train_transform)\n","\n","val_dataset = CityscapesDataset(root=\"/content/drive/MyDrive/Cityscapes/Cityspaces\",split=\"val\", transform=val_transform)\n","\n","\n","## DataLoader setup ##\n","\n","train_loader = DataLoader(\n","    train_dataset,\n","    batch_size=2,\n","    shuffle=True,\n","    num_workers=2,\n","    pin_memory=True\n",")\n","\n","val_loader = DataLoader(\n","    val_dataset,\n","    batch_size=2,\n","    shuffle=False,     # No shuffle for validation\n","    num_workers=2,\n","    pin_memory=True\n",")\n","\n"]},{"cell_type":"markdown","source":["Definition of DeepLab v2 model with pre-trained ResNet backbone"],"metadata":{"id":"DRZgxKcTPral"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"7CwLZL6efxh6"},"outputs":[],"source":["## MODEL DeepLabV2 ##\n","\n","affine_par = True\n","\n","\n","class Bottleneck(nn.Module):\n","    expansion = 4\n","\n","    def __init__(self, inplanes, planes, stride=1, dilation=1, downsample=None):\n","        super(Bottleneck, self).__init__()\n","        self.conv1 = nn.Conv2d(inplanes, planes, kernel_size=1, stride=stride, bias=False)\n","        self.bn1 = nn.BatchNorm2d(planes, affine=affine_par)\n","        for i in self.bn1.parameters():\n","            i.requires_grad = False\n","        padding = dilation\n","        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=1,\n","                               padding=padding, bias=False, dilation=dilation)\n","        self.bn2 = nn.BatchNorm2d(planes, affine=affine_par)\n","        for i in self.bn2.parameters():\n","            i.requires_grad = False\n","        self.conv3 = nn.Conv2d(planes, planes * 4, kernel_size=1, bias=False)\n","        self.bn3 = nn.BatchNorm2d(planes * 4, affine=affine_par)\n","        for i in self.bn3.parameters():\n","            i.requires_grad = False\n","        self.relu = nn.ReLU(inplace=True)\n","        self.downsample = downsample\n","        self.stride = stride\n","\n","    def forward(self, x):\n","        residual = x\n","        out = self.conv1(x)\n","        out = self.bn1(out)\n","        out = self.relu(out)\n","        out = self.conv2(out)\n","        out = self.bn2(out)\n","        out = self.relu(out)\n","        out = self.conv3(out)\n","        out = self.bn3(out)\n","        if self.downsample is not None:\n","            residual = self.downsample(x)\n","        out += residual\n","        out = self.relu(out)\n","\n","        return out\n","\n","\n","class ClassifierModule(nn.Module):\n","    def __init__(self, inplanes, dilation_series, padding_series, num_classes):\n","        super(ClassifierModule, self).__init__()\n","        self.conv2d_list = nn.ModuleList()\n","        for dilation, padding in zip(dilation_series, padding_series):\n","            self.conv2d_list.append(\n","                nn.Conv2d(inplanes, num_classes, kernel_size=3, stride=1, padding=padding,\n","                          dilation=dilation, bias=True))\n","\n","        for m in self.conv2d_list:\n","            m.weight.data.normal_(0, 0.01)\n","\n","    def forward(self, x):\n","        out = self.conv2d_list[0](x)\n","        for i in range(len(self.conv2d_list) - 1):\n","            out += self.conv2d_list[i + 1](x)\n","        return out\n","\n","\n","class ResNetMulti(nn.Module):\n","    def __init__(self, block, layers, num_classes):\n","        self.inplanes = 64\n","        super(ResNetMulti, self).__init__()\n","        self.conv1 = nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3,\n","                               bias=False)\n","        self.bn1 = nn.BatchNorm2d(64, affine=affine_par)\n","        for i in self.bn1.parameters():\n","            i.requires_grad = False\n","        self.relu = nn.ReLU(inplace=True)\n","        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1, ceil_mode=True)  # change\n","        self.layer1 = self._make_layer(block, 64, layers[0])\n","        self.layer2 = self._make_layer(block, 128, layers[1], stride=2)\n","        self.layer3 = self._make_layer(block, 256, layers[2], stride=1, dilation=2)\n","        self.layer4 = self._make_layer(block, 512, layers[3], stride=1, dilation=4)\n","        self.layer6 = ClassifierModule(2048, [6, 12, 18, 24], [6, 12, 18, 24], num_classes)\n","        for m in self.modules():\n","            if isinstance(m, nn.Conv2d):\n","                m.weight.data.normal_(0, 0.01)\n","            elif isinstance(m, nn.BatchNorm2d):\n","                m.weight.data.fill_(1)\n","                m.bias.data.zero_()\n","\n","    def _make_layer(self, block, planes, blocks, stride=1, dilation=1):\n","        downsample = None\n","        if (stride != 1\n","                or self.inplanes != planes * block.expansion\n","                or dilation == 2\n","                or dilation == 4):\n","            downsample = nn.Sequential(\n","                nn.Conv2d(self.inplanes, planes * block.expansion,\n","                          kernel_size=1, stride=stride, bias=False),\n","                nn.BatchNorm2d(planes * block.expansion, affine=affine_par))\n","        for i in downsample._modules['1'].parameters():\n","            i.requires_grad = False\n","        layers = []\n","        layers.append(\n","            block(self.inplanes, planes, stride, dilation=dilation, downsample=downsample))\n","        self.inplanes = planes * block.expansion\n","        for i in range(1, blocks):\n","            layers.append(block(self.inplanes, planes, dilation=dilation))\n","\n","        return nn.Sequential(*layers)\n","\n","    def forward(self, x):\n","        _, _, H, W = x.size()\n","\n","        x = self.conv1(x)\n","        x = self.bn1(x)\n","        x = self.relu(x)\n","        x = self.maxpool(x)\n","        x = self.layer1(x)\n","        x = self.layer2(x)\n","        x = self.layer3(x)\n","        x = self.layer4(x)\n","        x = self.layer6(x)\n","\n","        x = torch.nn.functional.interpolate(x, size=(H, W), mode='bilinear')\n","\n","        if self.training == True:\n","            return x, None, None\n","\n","        return x\n","\n","    def get_1x_lr_params_no_scale(self):\n","        \"\"\"\n","        This generator returns all the parameters of the net except for\n","        the last classification layer. Note that for each batchnorm layer,\n","        requires_grad is set to False in deeplab_resnet.py, therefore this function does not return\n","        any batchnorm parameter\n","        \"\"\"\n","        b = []\n","\n","        b.append(self.conv1)\n","        b.append(self.bn1)\n","        b.append(self.layer1)\n","        b.append(self.layer2)\n","        b.append(self.layer3)\n","        b.append(self.layer4)\n","\n","        for i in range(len(b)):\n","            for j in b[i].modules():\n","                jj = 0\n","                for k in j.parameters():\n","                    jj += 1\n","                    if k.requires_grad:\n","                        yield k\n","\n","    def get_10x_lr_params(self):\n","        \"\"\"\n","        This generator returns all the parameters for the last layer of the net,\n","        which does the classification of pixel into classes\n","        \"\"\"\n","        b = []\n","        if self.multi_level:\n","            b.append(self.layer5.parameters())\n","        b.append(self.layer6.parameters())\n","\n","        for j in range(len(b)):\n","            for i in b[j]:\n","                yield i\n","\n","    def optim_parameters(self, lr):\n","        return [{'params': self.get_1x_lr_params_no_scale(), 'lr': lr},\n","                {'params': self.get_10x_lr_params(), 'lr': 10 * lr}]\n","\n","\n","def get_deeplab_v2(num_classes=19, pretrain=True, pretrain_model_path='DeepLab_resnet_pretrained_imagenet.pth'):\n","    model = ResNetMulti(Bottleneck, [3, 4, 23, 3], num_classes)\n","\n","    if pretrain:\n","        print('Deeplab pretraining loading...')\n","        saved_state_dict = torch.load(pretrain_model_path)\n","\n","        new_params = model.state_dict().copy()\n","        for i in saved_state_dict:\n","            i_parts = i.split('.')\n","            new_params['.'.join(i_parts[1:])] = saved_state_dict[i]\n","        model.load_state_dict(new_params, strict=False)\n","\n","    return model\n","\n"]},{"cell_type":"markdown","metadata":{"id":"esXRVuLSgGqC"},"source":["This section presents two functions that\n","- Compute mean IoUs per class and mIoU\n","- Measure model latency and FPS"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jmFveUnCgHaR"},"outputs":[],"source":["def compute_miou(preds, labels, num_classes=19, device=\"cuda\"):\n","    \"\"\"\n","    Compute the mean Intersection over Union (mIoU) for semantic segmentation.\n","\n","    This function calculates the IoU for each class and returns both the mean IoU\n","    and the list of per-class IoUs. It handles the \"void\" label (255) by\n","    excluding it from false positive calculations.\n","    \"\"\"\n","\n","\n","    # Initialize variable that stores True Positives, False Positives and False Negatives\n","    tp = torch.zeros(num_classes, dtype=torch.int64, device=device)\n","    fp = torch.zeros(num_classes, dtype=torch.int64, device=device)\n","    fn = torch.zeros(num_classes, dtype=torch.int64, device=device)\n","\n","\n","    # Compute TP, FP, FN for each class\n","    for cls in range(num_classes):\n","        # True Positive\n","        tp[cls] += ((labels == cls) & (preds == cls)).sum()\n","        # False Positive\n","        fp[cls] += ((labels != cls) & (labels != 255) & (preds == cls)).sum()\n","        # False Negative\n","        fn[cls] += ((labels == cls) & (preds != cls)).sum()\n","\n","    iou_per_class = []\n","\n","    # Compute IoU for each class and store in a list\n","    for cls in range(num_classes):\n","        denom = tp[cls] + fp[cls] + fn[cls]\n","        iou = tp[cls].float() / (denom.float() + 1e-10)\n","        print(f\"Class {cls}: TP={tp[cls].item()}, FP={fp[cls].item()}, FN={fn[cls].item()}, IoU={iou.item():.4f}\")\n","        if denom > 0:  # only include classes with at least one pixel\n","            iou_per_class.append(iou.item())\n","\n","    mean_iou = np.mean(iou_per_class) if iou_per_class else 0.0\n","    return mean_iou, iou_per_class\n","\n","\n","def measure_latency_and_fps(model, device,iterations=1000, input_size=(3, 512, 1024)):\n","    \"\"\"\n","    Measure inference latency and FPS of a model.\n","    This function runs the model multiple times on a random input tensor and computes\n","    the average latency per forward pass and frames per second (FPS).\n","    \"\"\"\n","    model.eval().to(device)\n","\n","    # Create a random tensor\n","    image = torch.randn(1, *input_size).to(device)\n","\n","    latencies = []\n","    fps_list = []\n","\n","    with torch.no_grad():\n","        for _ in range(iterations):\n","            start = time.time()\n","            _ = model(image)    # forward pass\n","            if device == \"cuda\":\n","                torch.cuda.synchronize()\n","            end = time.time()\n","\n","            elapsed = end - start\n","            latencies.append(elapsed)\n","            fps_list.append(1.0 / elapsed)\n","\n","    mean_latency = np.mean(latencies) * 1000\n","    std_latency = np.std(latencies) * 1000\n","    mean_fps = np.mean(fps_list)\n","    std_fps = np.std(fps_list)\n","\n","    print(f\"Latency : {mean_latency:.2f} ms ± {std_latency:.2f} ms\")\n","    print(f\"FPS: {mean_fps:.2f} ± {std_fps:.2f}\")"]},{"cell_type":"markdown","source":["Function for the learning rate: polynomial learning rate."],"metadata":{"id":"42pUelB5TBQI"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"S60qdOolkWUg"},"outputs":[],"source":["## learning rate ##\n","\n","def poly_lr_scheduler(optimizer, init_lr, iter, lr_decay_iter=1,\n","                      max_iter=300, power=0.9):\n","    \"\"\"\n","    Polynomial decay of learning rate\n","        :param init_lr is base learning rate\n","        :param iter is a current iteration\n","        :param lr_decay_iter how frequently decay occurs, default is 1\n","        :param max_iter is number of maximum iterations\n","        :param power is a polymomial power\n","      Returns the scalar learning rate\n","    \"\"\"\n","\n","    lr = init_lr*(1 - iter/max_iter)**power\n","    optimizer.param_groups[0]['lr'] = lr\n","    return lr"]},{"cell_type":"markdown","source":["This section sets up the DeepLab v2 model with a pre-trained ResNet backbone,\n","defines the loss function, and configures the optimizer."],"metadata":{"id":"FUClg0bAIRm4"}},{"cell_type":"code","source":["## Model, loss function and optimizer ##\n","\n","# Initialize DeepLab v2 with pre-trained ResNet backbone\n","model = get_deeplab_v2(num_classes=19,pretrain=True, pretrain_model_path='/content/drive/MyDrive/2aMachineLearning/deeplab_resnet_pretrained_imagenet.pth')\n","model = model.to(device)\n","\n","# Cross-entropy loss function\n","criterion = torch.nn.CrossEntropyLoss(ignore_index=255)\n","\n","# SGD optimizer with momentum and weight decay\n","optimizer = torch.optim.SGD(model.parameters(),lr=0.0025, weight_decay=5e-4, momentum=0.9)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Z1S_SF1bIyd2","executionInfo":{"status":"ok","timestamp":1756912458430,"user_tz":-120,"elapsed":17697,"user":{"displayName":"GruppoBIxDB","userId":"02526103203990742405"}},"outputId":"620b997e-819a-4380-f657-461cde2e55a0"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Deeplab pretraining loading...\n"]}]},{"cell_type":"markdown","source":["Checkpoint Management, Device Setup, and AMP Initialization.\n","\n","This section prepares the training environment by:\n","   - Creating a directory to save model checkpoints\n","   - Selecting the computation device (GPU if available, else CPU).\n","   - Initializing PyTorch’s Automatic Mixed Precision (AMP) GradScaler"],"metadata":{"id":"gsOTvyBVOrPP"}},{"cell_type":"code","source":["## Setup directories, device, and AMP scaler ##\n","\n","# Directory to save model checkpoints\n","checkpoint_dir = \"/content/drive/MyDrive/2aMachineLearning/checkpoints\"\n","os.makedirs(checkpoint_dir, exist_ok=True)\n","max_checkpoints = 2\n","saved_checkpoints = deque()\n","\n","\n","# Select device (GPU if available, else CPU)\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","# Automatic Mixed Precision: GradScaler\n","scaler = torch.amp.GradScaler(device='cuda') if device.type == 'cuda' else None\n","\n","## Restore from latest checkpoint if available ##\n","latest_checkpoint = None\n","latest_epoch = -1\n","for fname in os.listdir(checkpoint_dir):\n","    if fname.startswith(\"checkpoint_epoch\") and fname.endswith(\".pt\"):\n","        epoch_num = int(fname.split(\"_epoch\")[1].split(\".\")[0])\n","        if epoch_num > latest_epoch:\n","            latest_epoch = epoch_num\n","            latest_checkpoint = os.path.join(checkpoint_dir, fname)\n","\n","start_epoch = 0\n","if latest_checkpoint:\n","    checkpoint = torch.load(latest_checkpoint, map_location=device, weights_only=False)     # Load checkpoint\n","\n","    # Restore model and optimizer state:\n","    model.load_state_dict(checkpoint['model_state_dict'])\n","    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n","\n","    # Restore AMP scaler if used\n","    if scaler and checkpoint.get('scaler_state_dict'):\n","        scaler.load_state_dict(checkpoint['scaler_state_dict'])\n","\n","    # Resume from next epoch\n","    start_epoch = checkpoint['epoch'] + 1\n","    print(f\" Restored from {latest_checkpoint}\")\n","else:\n","    print(\" No checkpoint found. Starting from scratch\")"],"metadata":{"id":"fXmvhryqGfUu","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1756912461590,"user_tz":-120,"elapsed":475,"user":{"displayName":"GruppoBIxDB","userId":"02526103203990742405"}},"outputId":"8df8ac3e-3026-4036-98a5-18a7b8067157"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":[" Restored from /content/drive/MyDrive/2aMachineLearning/checkpoints/checkpoint_epoch48.pt\n"]}]},{"cell_type":"markdown","source":["Training of the model"],"metadata":{"id":"ggqExiA6PdFN"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"EGTKKCWJJPgY","outputId":"051a500e-f8bd-448b-da57-1a2db2d65899"},"outputs":[{"output_type":"stream","name":"stderr","text":["/tmp/ipython-input-356305648.py:17: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n","  scaler = torch.cuda.amp.GradScaler()\n","/tmp/ipython-input-356305648.py:33: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n","  with torch.cuda.amp.autocast():\n"]}],"source":["\n","## Variables for training progress ##\n","\n","num_epochs = 50   # number of epochs\n","num_classes = 19    # Number of segmentation classes\n","\n","# Best mIoU, corresponding checkpoint and list for storing evaluation of loss function on training dataset during epochs\n","best_miou = 0.0\n","best_epoch_ckpt = None\n","epoch_loss_list = []\n","\n","\n","## hyperparameters ##\n","\n","initial_lr = 0.025    # Initial learning rate\n","alpha = 0.4   # Weight coefficient for auxiliary loss\n","\n","scaler = torch.cuda.amp.GradScaler()\n","\n","## training loop ##\n","\n","for epoch in range(start_epoch, num_epochs):\n","    model.train()\n","    total_loss = 0.0\n","    lr = poly_lr_scheduler(optimizer, initial_lr, epoch)\n","\n","    for batch_idx, (images, labels) in enumerate(train_loader):\n","        images = images.to(device, non_blocking=True)\n","        labels = labels.long().to(device, non_blocking=True)\n","\n","        optimizer.zero_grad()\n","\n","        # Forward step\n","        with torch.cuda.amp.autocast():\n","            outputs = model(images)\n","\n","            if isinstance(outputs, (list, tuple)):\n","                main_pred, *aux_preds = outputs\n","                main_pred = F.interpolate(main_pred, size=labels.shape[1:], mode='bilinear', align_corners=False)\n","\n","                # Main loss\n","                loss = criterion(main_pred, labels)\n","\n","                # Auxiliary losses\n","                for aux in aux_preds:\n","                    if aux is not None:\n","                      aux = F.interpolate(aux, size=labels.shape[1:], mode='bilinear', align_corners=False)\n","                      loss += alpha * criterion(aux, labels)\n","            else:\n","                main_pred = F.interpolate(outputs, size=labels.shape[1:], mode='bilinear', align_corners=False)\n","                loss = criterion(main_pred, labels)\n","\n","        # Backward step\n","        scaler.scale(loss).backward()\n","        scaler.step(optimizer)\n","\n","        scaler.update()\n","\n","        total_loss += loss.item()\n","\n","        del images, labels, outputs, loss\n","        torch.cuda.empty_cache()\n","        gc.collect()\n","\n","    epoch_loss = total_loss/len(train_loader)\n","    epoch_loss_list.append(epoch_loss)\n","\n","\n","    ## Miou on validation set ##\n","\n","    all_predictions = []\n","    all_labels = []\n","\n","    model.eval()\n","    with torch.no_grad():\n","        for images, labels in val_loader:\n","            images = images.to(device, non_blocking=True)\n","            labels = labels.long().to(device, non_blocking=True)\n","\n","            outputs = model(images)\n","            if isinstance(outputs, (list, tuple)):\n","                main_pred = outputs[0]\n","            else:\n","                main_pred = outputs\n","\n","            main_pred = F.interpolate(main_pred, size=labels.shape[1:], mode=\"bilinear\", align_corners=False)\n","\n","            probabilities = torch.nn.functional.softmax(main_pred, dim=1)\n","            predictions = torch.argmax(probabilities, dim=1)\n","\n","            all_predictions.append(predictions)\n","            all_labels.append(labels)\n","\n","    all_predictions = torch.cat(all_predictions, dim=0)\n","    all_labels = torch.cat(all_labels, dim=0)\n","\n","    epoch_miou, IoU_per_class = compute_miou(all_predictions, all_labels, num_classes=num_classes)\n","    print(f\" End Epoch {epoch+1} — Loss: {epoch_loss:.4f}, mIoU: {epoch_miou:.4f}, LR at the end of epoch: {lr:.6f}\")\n","\n","    ## Saving checkpoints every 3 epochs ##\n","    if (epoch + 1) % 3 == 0:\n","        checkpoint_filename = f\"checkpoint_epoch{epoch+1}.pt\"\n","        checkpoint_path = os.path.join(checkpoint_dir, checkpoint_filename)\n","\n","        # Save model, optimizer, scaler, loss, and mIoU\n","        torch.save({\n","            'epoch': epoch,\n","            'model_state_dict': model.state_dict(),\n","            'optimizer_state_dict': optimizer.state_dict(),\n","            'scaler_state_dict': scaler.state_dict(),\n","            'loss': epoch_loss,\n","            'miou': epoch_miou,\n","        }, checkpoint_path)\n","        saved_checkpoints.append(checkpoint_path)\n","        print(f\"Checkpoint saved: {checkpoint_filename}\")\n","\n","        while len(saved_checkpoints) > max_checkpoints:\n","            old_ckpt = saved_checkpoints.popleft()\n","            if os.path.exists(old_ckpt):\n","                os.remove(old_ckpt)\n","                print(f\"Removed old checkpoint: {os.path.basename(old_ckpt)}\")\n","\n","    ## Saving the best model ##\n","    if epoch_miou > best_miou:  # Update best mIoU\n","        best_miou = epoch_miou\n","        best_epoch_ckpt = os.path.join(checkpoint_dir, \"2a_best_epoch.pt\")\n","\n","        # Save model, optimizer, scaler, loss, and mIoU as the best checkpoin\n","        torch.save({\n","            'epoch': epoch,\n","            'model_state_dict': model.state_dict(),\n","            'optimizer_state_dict': optimizer.state_dict(),\n","            'scaler_state_dict': scaler.state_dict(),\n","            'loss': epoch_loss,\n","            'miou': epoch_miou,\n","        }, best_epoch_ckpt)\n","        print(f\"New best model saved: {best_epoch_ckpt} con mIoU {best_miou:.4f}\")\n","\n","\n","print(f\"epoch_loss_list: {epoch_loss_list}\")\n","\n"]},{"cell_type":"markdown","source":["Computing metrics such as FLOPs, latency and FPS of the final model."],"metadata":{"id":"7icA537iSsBJ"}},{"cell_type":"code","source":["## FLOPs, latency e FPS on the trained model ##\n","model.eval()\n","image = torch.zeros((1, 3, 512, 1024)).to(device)\n","\n","# FLOPs of the model\n","flops = FlopCountAnalysis(model, image)\n","print(flop_count_table(flops))\n","\n","# Measure model latency and FPS\n","measure_latency_and_fps(model, device=device)"],"metadata":{"id":"ZYfRYMZKFg-K"},"execution_count":null,"outputs":[]}],"metadata":{"colab":{"provenance":[],"machine_shape":"hm","gpuType":"T4"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":0}